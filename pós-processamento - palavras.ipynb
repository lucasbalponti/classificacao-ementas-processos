{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Lucas\n",
      "[nltk_data]     Alponti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import re\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o objeto dataframe\n",
    "with open(r'df-pos-processado-caracteres.pickle', 'rb') as picklefile:\n",
    "    df = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionado apenas as linhas assunto e texto tratado, e removendo as duplicadas\n",
    "df = df[['Assunto', 'Texto tratado']]\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo, com base apenas na coluna 'Texto tratado', os valores repetidos\n",
    "v = df['Texto tratado'].value_counts()\n",
    "repetidos = df[df['Texto tratado'].isin(v.index[v.gt(1)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(list(repetidos.index), axis=0, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizando a coluna texto tratado\n",
    "df['Tokenizadas'] = [str(t).split() for t in df['Texto tratado']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo as stopwords mais comuns para português\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um dicionário, que terá melhor performance ao ser percorrido\n",
    "dict_stopwords = Counter(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo as stopwords\n",
    "for i in range(len(df)):\n",
    "    df['Tokenizadas'][i] = [t for t in df['Tokenizadas'][i] if dict_stopwords[t]==0 and len(t)>2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma lista com todas as palavras\n",
    "lista_palavras = []\n",
    "for row in df['Texto tratado']:\n",
    "    for word in str(row).split():\n",
    "        lista_palavras.append(word)\n",
    "\n",
    "counts = Counter(lista_palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando as palavras pouco comuns (menos de 100 ocorrências)\n",
    "lista_pouco_comuns = [elem for elem in counts.most_common() if elem[1]<=10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5207713697611012"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando o percentual destas palavras em relação ao total\n",
    "100*len(lista_pouco_comuns)/len(lista_palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo as palavras pouco frequentes\n",
    "for i in range(len(df)):\n",
    "    df['Tokenizadas'][i] = [t for t in df['Tokenizadas'][i] if counts[t]>10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando lista com todas as palavras para encontrar palavras para corrigir\n",
    "lista_palavras_corrigir = []\n",
    "for row in df['Tokenizadas']:\n",
    "    for word in row:\n",
    "        lista_palavras_corrigir.append(word)\n",
    "\n",
    "counts2 = Counter(lista_palavras_corrigir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percorrendo a lista de palavras, selecionando apenas as finalizadas em ã ou ç\n",
    "# ou que possuem caracteres não convencionais (^~´`)\n",
    "lista_palavras_corrigir = [t for t in lista_palavras_corrigir if re.search(r'[\\^~´`]|ã$|ç$', t)]\n",
    "lista_palavras_corrigir = list(set(lista_palavras_corrigir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluindo da lista palavras que não devem ser removidas\n",
    "lista_palavras_corrigir.remove('manhã')\n",
    "lista_palavras_corrigir.remove('mairiporã')\n",
    "lista_palavras_corrigir.remove('irmã')\n",
    "lista_palavras_corrigir.remove('guardiã')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo as palavras acima\n",
    "dict_corrigir = Counter(lista_palavras_corrigir)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df['Tokenizadas'][i] = [t for t in df['Tokenizadas'][i] if dict_corrigir[t]==0 and len(t)>2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escrevendo lista de termos jurídicos para serem removidos\n",
    "lista_termos_juridicos = [\n",
    "    \"inciso\",\n",
    "    \"incisos\",\n",
    "    \"inc\",\n",
    "    \"incs\",\n",
    "    \"artigo\",\n",
    "    \"artigos\",\n",
    "    \"art\",\n",
    "    \"arts\",\n",
    "    \"parágrafo\",\n",
    "    \"parágrafos\",\n",
    "    \"par\",\n",
    "    \"pars\"\n",
    "]\n",
    "\n",
    "dict_termos_juridicos = Counter(lista_termos_juridicos)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df['Tokenizadas'][i] = [t for t in df['Tokenizadas'][i] if dict_termos_juridicos[t]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo numerais romanos\n",
    "for i in range(len(df)):\n",
    "    df['Tokenizadas'][i] = [t for t in df['Tokenizadas'][i] if not re.findall(\n",
    "                            \"\\\\b(?=[MDCLXVIΙ])M{0,4}(CM|CD|D?C{0,3})(XC|XL|L?X{0,3})([IΙ]X|[IΙ]V|V?[IΙ]{0,3})\\\\b\\\\.?\",\n",
    "                            flags=re.I,\n",
    "                            string=t)\n",
    "                            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo linhas em que todas as palavras foram removidas\n",
    "df.drop(df[df['Tokenizadas'].apply(lambda x: len(str(x))==0)].index, axis=0, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o objeto dataframe\n",
    "with open(r'df-pos-processado-palavras.pickle', 'wb') as picklefile:\n",
    "    pickle.dump(df, picklefile, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assunto</th>\n",
       "      <th>Texto tratado</th>\n",
       "      <th>Tokenizadas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Direito Tributário</td>\n",
       "      <td>recursos extraordinários ma apelaç ne ô í coma...</td>\n",
       "      <td>[recursos, extraordinários, santo, andré, reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Direito Tributário</td>\n",
       "      <td>imposto propriedade predial e territorial urba...</td>\n",
       "      <td>[propriedade, predial, territorial, urbana, pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Direito Tributário</td>\n",
       "      <td>acórdão tributo imposto predial e territorial ...</td>\n",
       "      <td>[acórdão, tributo, predial, territorial, urban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Direito Tributário</td>\n",
       "      <td>acórdão mandado de segurança iptu progressivid...</td>\n",
       "      <td>[acórdão, segurança, progressividade, paulo, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Direito Tributário</td>\n",
       "      <td>da função social do imóvel para se tornar um t...</td>\n",
       "      <td>[função, social, tornar, tributo, natureza, es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81407</th>\n",
       "      <td>Direito Civil</td>\n",
       "      <td>indenizatória contexto probatório que enseja o...</td>\n",
       "      <td>[probatório, enseja, reconhecimento, responsab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81408</th>\n",
       "      <td>Direito Civil</td>\n",
       "      <td>acórdão processo ação indenizatóría afastada a...</td>\n",
       "      <td>[acórdão, processo, ação, afastada, pretensão,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81409</th>\n",
       "      <td>Direito Civil</td>\n",
       "      <td>penhora direito de preferência anterioridade d...</td>\n",
       "      <td>[penhora, preferência, anterioridade, penhora,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81410</th>\n",
       "      <td>Direito Civil</td>\n",
       "      <td>agravo df instrumento ação de indenização em f...</td>\n",
       "      <td>[agravo, ação, fase, execução, assistência, au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81411</th>\n",
       "      <td>Direito Civil</td>\n",
       "      <td>vistos relatados e discutidos estes autos de a...</td>\n",
       "      <td>[relatados, autos, apelação, sendo, apelante, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81412 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Assunto                                      Texto tratado  \\\n",
       "0      Direito Tributário  recursos extraordinários ma apelaç ne ô í coma...   \n",
       "1      Direito Tributário  imposto propriedade predial e territorial urba...   \n",
       "2      Direito Tributário  acórdão tributo imposto predial e territorial ...   \n",
       "3      Direito Tributário  acórdão mandado de segurança iptu progressivid...   \n",
       "4      Direito Tributário  da função social do imóvel para se tornar um t...   \n",
       "...                   ...                                                ...   \n",
       "81407       Direito Civil  indenizatória contexto probatório que enseja o...   \n",
       "81408       Direito Civil  acórdão processo ação indenizatóría afastada a...   \n",
       "81409       Direito Civil  penhora direito de preferência anterioridade d...   \n",
       "81410       Direito Civil  agravo df instrumento ação de indenização em f...   \n",
       "81411       Direito Civil  vistos relatados e discutidos estes autos de a...   \n",
       "\n",
       "                                             Tokenizadas  \n",
       "0      [recursos, extraordinários, santo, andré, reco...  \n",
       "1      [propriedade, predial, territorial, urbana, pr...  \n",
       "2      [acórdão, tributo, predial, territorial, urban...  \n",
       "3      [acórdão, segurança, progressividade, paulo, e...  \n",
       "4      [função, social, tornar, tributo, natureza, es...  \n",
       "...                                                  ...  \n",
       "81407  [probatório, enseja, reconhecimento, responsab...  \n",
       "81408  [acórdão, processo, ação, afastada, pretensão,...  \n",
       "81409  [penhora, preferência, anterioridade, penhora,...  \n",
       "81410  [agravo, ação, fase, execução, assistência, au...  \n",
       "81411  [relatados, autos, apelação, sendo, apelante, ...  \n",
       "\n",
       "[81412 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
